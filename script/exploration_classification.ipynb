{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On cherche à garder les meilleures variables pour notre modèle de classification :\n",
    "- On va donc utiliser les features importances de randomforest et puis ne l'entraîner que sur les meilleures features pour que le modèle ne soit pas trop lourd\n",
    "- **Un enjeu clef est de voir si les données de l'open data socio-économique de l'INSEE joue sur les étiquettes DPE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "from pre_processing import preprocess_data, import_data\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\M2\\Python\\Projet\\pre_processing.py:15: DtypeWarning: Columns (33,35,38,51,57,69,72,99,115) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(chemin, sep=';')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import réussi\n",
      "(287165, 131)\n",
      "2021-07-01\n",
      "2024-09-16\n",
      "0         2024-08-30\n",
      "1         2024-07-25\n",
      "2         2024-08-13\n",
      "3         2024-07-30\n",
      "4         2024-09-11\n",
      "             ...    \n",
      "287160    2024-06-27\n",
      "287161    2024-03-01\n",
      "287162    2024-03-04\n",
      "287163    2024-06-24\n",
      "287164    2024-02-29\n",
      "Name: Date_réception_DPE, Length: 287165, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = import_data('data/merged_69.csv') # Si vous voulez re-executer le code, il faut changer le chemin du fichier par ../data/dataset_M2_enedis.csv\n",
    "print(df.shape)\n",
    "# Entrée ayant la date réception la plus petite et la plus grande\n",
    "# On recherche les dates\n",
    "print(df['Date_réception_DPE'].min())\n",
    "print(df['Date_réception_DPE'].max())\n",
    "print(df['Date_réception_DPE'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1138\n",
      "0         1121\n",
      "1         1085\n",
      "2         1104\n",
      "3         1090\n",
      "4         1133\n",
      "          ... \n",
      "287160    1059\n",
      "287161     960\n",
      "287162     961\n",
      "287163    1056\n",
      "287164     959\n",
      "Name: Date_réception_DPE, Length: 287165, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "df = preprocess_data(df, sauvegarde=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 287165 entries, 0 to 287164\n",
      "Columns: 103 entries, Ubat_W/m²_K to Complément_d'adresse_logement\n",
      "dtypes: float64(103)\n",
      "memory usage: 225.7 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df.head()\n",
    "print(df.info()) # Voir le type des colonnes : ne devrait avoir que des float64 car Encoding des variables catégorielles\n",
    "# Définition des variables explicatives et de la variable cible\n",
    "target = \"Etiquette_DPE\"\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement du modèle...\n"
     ]
    }
   ],
   "source": [
    "RF_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "print(\"Entrainement du modèle...\")\n",
    "RF_model.fit(X_train, y_train)\n",
    "y_pred = RF_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultats du modèle...\n",
      "Accuracy: 0.9949390597794544\n",
      "Meilleures features...\n",
      "1. Conso_5_usages_par_m²_é_primaire: 0.23084911045301518\n",
      "2. Conso_5_usages/m²_é_finale: 0.117427696805111\n",
      "3. Emission_GES_5_usages_par_m²: 0.10900606994831526\n",
      "4. Etiquette_GES: 0.09830970376943249\n",
      "5. Coût_éclairage: 0.02219566954635474\n",
      "Si on doit réduire la dimensions, il ne faudra garde que les 5 features ci-dessus\n"
     ]
    }
   ],
   "source": [
    "print(\"Résultats du modèle...\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Meilleures features...\")\n",
    "feature_importances = RF_model.feature_importances_\n",
    "indices = np.argsort(feature_importances)[::-1]\n",
    "top_n = 5  # Limite à 10 -> avec 10 features, on a déjà 0.991 d'accuracy, avec 5 features, on a 0.987\n",
    "top_features = X.columns[indices[:top_n]]\n",
    "top_importances = feature_importances[indices[:top_n]]\n",
    "for i, feature in enumerate(top_features):\n",
    "  print(f\"{i+1}. {feature}: {top_importances[i]}\")\n",
    "\n",
    "print(f\"Si on doit réduire la dimensions, il ne faudra garde que les {top_n} features ci-dessus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Essayons de réentraîner le modèle avec ces 10 features et regardons si l'accuracy à changer, elle est égal à 99%, ce qui est déjà très haut**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement du modèle...\n",
      "Résultats du modèle...\n",
      "Accuracy: 0.9867208357515961\n"
     ]
    }
   ],
   "source": [
    "RF_model_alleger = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "print(\"Entrainement du modèle...\")\n",
    "X_train, X_test = X_train[top_features], X_test[top_features]\n",
    "RF_model_alleger.fit(X_train, y_train)\n",
    "y_pred = RF_model_alleger.predict(X_test)\n",
    "\n",
    "print(\"Résultats du modèle...\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**On voit que le modèle garde une accuracy très élevé (99%), même en ne retenant que les 10 premières variables, essayons avec 5**\n",
    "\n",
    "-> Nous avons 0.987, on va donc garder un modèle avec les 5 meilleures features, essayons aussi de baisser le nombre d'estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrainement du modèle...\n",
      "Résultats du modèle...\n",
      "Accuracy: 0.9867208357515961\n"
     ]
    }
   ],
   "source": [
    "RF_model_alleger = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "print(\"Entrainement du modèle...\")\n",
    "X_train, X_test = X_train[top_features], X_test[top_features]\n",
    "RF_model_alleger.fit(X_train, y_train)\n",
    "y_pred = RF_model_alleger.predict(X_test)\n",
    "\n",
    "print(\"Résultats du modèle...\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lorsqu'on passe de 100 à 10 estimator, l'accuracy ne change pas, on va donc en garder que 10**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modèle sauvegardé avec succès sous : RF_alleger_Classification_Etiquette.pkl\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "  with open('RF_alleger_Classification_Etiquette.pkl', 'wb') as file:\n",
    "      pickle.dump(RF_model_alleger, file)\n",
    "  print(f\"Modèle sauvegardé avec succès sous : {'RF_alleger_Classification_Etiquette.pkl'}\")\n",
    "except Exception as e:\n",
    "  print(f\"Erreur lors de la sauvegarde du modèle : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Conso_5_usages_par_m²_é_primaire',\n",
       " 'Conso_5_usages/m²_é_finale',\n",
       " 'Emission_GES_5_usages_par_m²',\n",
       " 'Etiquette_GES',\n",
       " 'Coût_éclairage']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(top_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "M1Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
